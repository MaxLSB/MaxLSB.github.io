---
title: "Flash Attention 2"
description: "Implementation of Flash Attention 2 with sliding window support using Triton for efficient attention computation."
url: "https://github.com/MaxLSB/flash-attn2"
featured: false
techs: ["Triton", "Transformers", "GPU Optimization"]
additionalLinks:
  - label: "GitHub"
    url: "https://github.com/MaxLSB/flash-attn2"
    platform: "GitHub"
---
